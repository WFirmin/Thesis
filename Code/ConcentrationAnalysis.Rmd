---
title: "Labor Market Concentration Analysis"
author: "Will Firmin"
output:
  pdf_document: default
  html_notebook: default
---


## Data


I use data from the US Census Bureau on quarterly Job to Job Flows (J2J) at the Metro Statistical Area level from 2000-2019.  In addition, I filter down to two groups that are more experience a greater bite from the minimum wage: young workers aged 18-22 and workers in either the General Merchandise industry (NAICS 452) or Food Services (NAICS 72).  From this, I use the ratio of stable job to job flows "EES" (originating from the area and industry or age) to separations into non employment "ENSep" as a metric for labor market concentration (following pages 1019-1020 of Alan Manning's book).  Higher values indicate higher competition and lower concentration.

##### EES: 
A worker, i, is defined as having a Stable Job-to-Job Flow with Continuous Employment from a firm, a, (to another firm, b) in a quarter, t, if i

- has a beginning-of-quarter main job with a in t, AND

- does not receive earnings from a in t+1, AND

- receives earnings from a in t-2, AND

- has an end-of-quarter main job with b in t, AND

- does not receive earnings from b in t-1, AND

- receives earnings from b in t+2.

##### ENSep:
A worker, i, is defined as having a Separation to Nonemployment from a firm, a, in a quarter, t, if i

- has a beginning-of-quarter main job with a in t AND

- has no end-of-quarter main job with any firm in t.



This is joined with data from the Quarterly Census of Employment and Wages (QCEW) for both the General Merchandise industry and the area overall.  This gives industry employment (dependent variable) and total number of establishments, total employment, total summed quarterly wages, and total average weekly wage (over all industries as control variables).

Minimum Wage data is from the US Department of Labor and at the state level.  I am still trying to find data on the cities that have their own minimum wage in place.  Since most of these cities are in California, I ran a second analysis without any Californian data (removed 26 out of 376 metro areas).  This reduced the p-value of the coefficient of interest in the fixed effects model from 0.0088 to 0.075.

The final fixed effects model is 

$log(IND\_EMP_{i,t})=\beta_1 log(MW_{i,t})+\beta_2 COMPETITION_{i,t}+\beta_3 log(MW_{i,t})\times COMPETITION_{i,t} + \beta_4log(TOT\_ESTAB_{i,t}) + \beta_5log(TOT\_EMP_{i,t}) + \beta_6log(TOT\_WAGES_{i,t})+\beta_7log(TOT\_AVG\_WAGE_{i,t}) + \delta_{year} + \mu_{state} +\epsilon_i$

for location $i$, quarter $t$.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, cache=F, message=F, warning=F, fig.show="hold", out.width="50%")
```

```{r}
rm(list=ls())
library(tidyverse)
library(plm)
library(lmtest)
library(car)
library(gplots)


data1 = read.csv("ConcData.csv")
```


```{r}
#Analysis/Testing
data = data1

#filter out california:
data = data[data$state != "CA" & data$num_states == 1 & data$quarterlyMW == 1,]

# filter out unwanted variables:
data = data[data$agegrp == "A01",]
#data = data[data$agegrp == "A00" & data$industry %in% c("72","44-45"),]
# & data$industry %in% c("72","44-45")
data$MainB_prop_1[is.na(data$MainB_prop_1)] = 1

# Concentration metrics:
data$competition = data$EES / data$ENSep
#data$competition = data$EE / data$ENFullQ

data$ref_wage = data$avg_wkly_wage / data$minimum_wage
data$TOTAL_ref_wage = data$TOTAL_avg_wkly_wage / data$minimum_wage
#data$inv_ref_wage = 1/data$ref_wage

# lower observations with MW 5.15 or 7.25: sample to 3000
# hist(data$minimum_wage,main="Minimum Wage, Raw Data",xlab="Minimum Wage")
# data515 = data[data$minimum_wage == 5.15,]
# data725 = data[data$minimum_wage == 7.25,]
# data = data[data$minimum_wage != 5.15 & data$minimum_wage != 7.25,]
# set.seed(123)
# data515 = data515[sample(nrow(data515),1000),]
# data725 = data725[sample(nrow(data725),2000),]
# data = rbind(data, data515, data725)

# Dependent variable:
hist(log(data$MainB), xlab="Log Employment", main="Employment")

# Variable of high interest:
hist(log(data$minimum_wage),main="Minimum Wage",xlab="Log Minimum Wage")
hist(log(data$competition), xlab="Log Competition Metric", main="Labor Market Competition Metric")

# Control variables:
hist(log(data$TOTAL_qtrly_estabs_count), xlab=" Log Number of Establishments",main="Number of Establishments, all Industries")
hist(log(data$TOTAL_month1_emplvl), xlab="Log Employment",main="Employment, all Industries")
hist(log(data$TOTAL_total_qtrly_wages), xlab="Log Wages",main="Total Wages, all Industries")
hist(log(data$TOTAL_avg_wkly_wage), xlab="Log Wage",main="Avg Weekly Wage, all Industries")
hist(data$metro_size, xlab="Metro Population",main="Metro Population")

formula = as.formula("log(MainB) ~ log(minimum_wage) + log(competition) + log(minimum_wage):log(competition) +
                     log(TOTAL_qtrly_estabs_count) + log(TOTAL_month1_emplvl) + log(TOTAL_total_qtrly_wages) + 
                     log(TOTAL_avg_wkly_wage) + TOTAL_ref_wage + metro_size + log(MainB_1) + log(MainB_prop_1) + 
                     as.factor(quarter)")


labelCols = c("year","quarter","state","geography","industry")
logCols = c("avg_wkly_wage","MainB","MainB_prop_1","MainB_1","TOTAL_qtrly_estabs_count","TOTAL_month1_emplvl","TOTAL_total_qtrly_wages","TOTAL_avg_wkly_wage",
            "minimum_wage","competition")
otherCols = c("metro_size","TOTAL_ref_wage")

data = data[c(labelCols, logCols, otherCols)]
data = na.omit(data)

for(col in logCols){
  data = data[data[[col]] > 0 & data[[col]] < Inf,]
}

# data = data[data$MainB > 0 & data$minimum_wage > 0 & data$competition > 0 & data$TOTAL_qtrly_estabs_count > 0 &
#               data$TOTAL_month1_emplvl > 0 & data$TOTAL_total_qtrly_wages > 0 & data$TOTAL_avg_wkly_wage > 0,]
# data = data[data$MainB < Inf & data$minimum_wage < Inf & data$competition < Inf & data$TOTAL_qtrly_estabs_count < Inf &
#               data$TOTAL_month1_emplvl < Inf & data$TOTAL_total_qtrly_wages < Inf & data$TOTAL_avg_wkly_wage < Inf,]
# data = data[!is.na(data$MainB) & !is.na(data$minimum_wage) & !is.na(data$competition) &
#               !is.na(data$TOTAL_qtrly_estabs_count) & !is.na(data$TOTAL_month1_emplvl) &
#               !is.na(data$TOTAL_total_qtrly_wages) & !is.na(data$TOTAL_avg_wkly_wage),]
# data = data[!is.na(data$year) & !is.na(data$quarter) & !is.na(data$area_title),]
# 
# data = data[data$month1_emplvl > 0 & data$month1_emplvl < Inf & !is.na(data$month1_emplvl),]
```


### Linear Model

```{r}
reg1 = lm(formula, data=data)
summary(reg1)
```


### Pooled Model

```{r}
panelData = data
panelData$date = panelData$year + (panelData$quarter-1)/4
panelData$areaQuarter = paste(data$geography, data$quarter)
panelData$areaQuarterState = paste(panelData$areaQuarter, panelData$state)
panelData$areaQuarterIndustry = paste(panelData$areaQuarter, data$industry)

panelData = panelData[!is.na(panelData$date),]
panelData = pdata.frame(panelData, index=c("year","industry","areaQuarterState"))
#panelData = pdata.frame(panelData, index=c("year","state","areaQuarterIndustry"))
  
reg.pooled = plm(formula, data=panelData, model="pooling")
summary(reg.pooled)
```

### Fixed Effects Model

```{r}
reg.fixed = plm(formula, data=panelData, model="within", effect="twoways")
summary(reg.fixed)
#fixef(reg.fixed)

#Test if fixed effects are needed: Answer = Yes
pFtest(reg.fixed, reg.pooled)
```

### Random Effects

```{r}
#random effects
#reg.random = plm(formula, data=panelData, model="random", effect="twoways")
#summary(reg.random)
#test which is better:
#phtest(reg.fixed, reg.random)
```

```{r}
# Groups by concentration:

formula2 = as.formula("log(MainB) ~ log(minimum_wage) + log(TOTAL_qtrly_estabs_count) + 
                     log(TOTAL_month1_emplvl) + log(TOTAL_total_qtrly_wages) + log(TOTAL_avg_wkly_wage) +
                     TOTAL_ref_wage + metro_size + log(MainB_1) + log(MainB_prop_1) + as.factor(quarter)")


library(ggplot2)

getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}


ci = data.frame()
#probs = seq(0,1,0.1)
probs = c(0,0.1,0.7,1)
q = quantile(panelData$competition, probs=probs, na.rm=T)
for(i in (1:(length(probs)-1))){
  dataQ = panelData[panelData$competition < q[i+1] & panelData$competition >= q[i],]
  tc = qt(0.975, dim(dataQ)[1])
  r = plm(formula2, data=dataQ, model="within", effect="twoways")
  s = summary(r)$coefficients
  vars = dimnames(s)[[1]]
  #print(summary(r)$coefficients)
  point = s[vars == "log(minimum_wage)",1]
  #point = summary(r)$coefficients[1,1]
  t = s[vars == "log(minimum_wage)",2]
  #t = summary(r)$coefficients[1,2]
  fixedS = summary(reg.fixed)$coefficients
  fixedVars = dimnames(fixedS)[[1]]
  fixedPoint = fixedS[fixedVars == "log(minimum_wage)",1]
  fixedPointComp = fixedS[fixedVars == "log(minimum_wage):log(competition)",1]
  med = median(dataQ$competition)
  
  ci = rbind(ci, c(log(med), point, point - tc*t, point + tc*t, fixedPoint + fixedPointComp*log(med)))
}

colnames(ci) = c("Log Competition","MW Elasticity of Employment","lower","upper", "Estimated Elasticity")
ggplot(ci, aes(`Log Competition`, `MW Elasticity of Employment`)) +        # ggplot2 plot with confidence intervals
  geom_line(aes(x=`Log Competition`, y=`Estimated Elasticity`, color="red")) +
  geom_point() +
  geom_errorbar(aes(ymin = lower, ymax = upper))
  

# # Notice the high number of 0's:  Might explain last estimate in plot
# hist(log(data$competition),breaks=200, main="Competition Metric, Higher Granularity",xlab="Log Competition")
# 
# formula3 = as.formula("log(MainB) ~ log(minimum_wage) + log(TOTAL_qtrly_estabs_count) + 
#                      log(TOTAL_month1_emplvl) + log(TOTAL_total_qtrly_wages) + log(TOTAL_avg_wkly_wage) +
#                      TOTAL_ref_wage + metro_size")
# 
# ci = data.frame()
# indus = unique(data$industry)
# for(i in c("All",indus)){
#   if(i != "All"){
#     dataQ = panelData[panelData$industry == i,]
#   } else{
#     dataQ = panelData
#   }
#   tc = qt(0.975, dim(dataQ)[1])
#   r = plm(formula3, data=dataQ, model="within", effect="twoways")
#   #print(summary(r)$coeffici3ts)
#   point = summary(r)$coefficients[1,1]
#   t = summary(r)$coefficients[1,2]
#   ci = rbind(ci, c(i, point, point - tc*t, point + tc*t, median(dataQ$competition)))
# }
# 
# colnames(ci) = c("Industry","MW Elasticity of Employment","lower","upper","competition")
# ci[(2:5)] = lapply(ci[(2:5)],as.numeric)
# 
# ggplot(ci, aes(x=Industry, y=`MW Elasticity of Employment`)) +
#   geom_point() +
#   geom_errorbar(aes(ymin = lower, ymax = upper)) +
#   theme(axis.text.x = element_text(angle=-30))
# 
# 
# for(i in indus){
#   dataI = data[data$industry == i,]
#   hist(log(dataI$competition), breaks=200, main=i)
# }
# 
# probs=c(0,0.1,0.4,0.7,0.9,1)
# for(i in indus){
#   ci = data.frame()
#   dataI = panelData[panelData$industry == i,]
#   q = unique(quantile(dataI$competition, probs=probs))
#   for(j in (1:(length(probs)-1))){
#     dataQ = dataI[dataI$competition <= q[j+1] & dataI$competition > q[j],]
#     tc = qt(0.975, dim(dataQ)[1])
#     r = plm(formula3, data=dataQ, model="within", effect="twoways")
#     point = summary(r)$coefficients[1,1]
#     t = summary(r)$coefficients[1,2]
#     ci = rbind(ci, c(mean(log(dataQ$competition)), point, point - tc*t, point + tc*t))
#   }
#   
#   colnames(ci) = c("Log Competition","MW Elasticity of Employment","lower","upper")
#   ggplot(ci, aes(`Log Competition`, `MW Elasticity of Employment`)) +        # ggplot2 plot with confidence intervals
#     geom_point() +
#     geom_errorbar(aes(ymin = lower, ymax = upper)) + ggtitle(i)
#   
# }
# 
regAll = plm(formula2, data=panelData, model="within", effect="twoways")
summary(regAll)

```

