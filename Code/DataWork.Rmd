---
title: "Thesis Work"
author: "William Firmin"
output:
  pdf_document: default
  html_notebook: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, cache=F, message=F, warning=F, fig.show="hold", out.width="50%")
```

```{r}
library(ipumsr)
library(stringr)
library(dplyr)
rm(list=ls())
ddi = read_ipums_ddi("usa_00001.xml")
data = read_ipums_micro(ddi)
data = filter(data, str_sub(data$INDNAICS,1,3)=="452")
data = filter(data, !is.na(data$PWCOUNTY))
write.csv(data, "usa.csv", row.names=FALSE)
test = read.csv("usa.csv")
```

```{r}
#J2J, employment combination

#J2J: US Census Bureau - https://ledextract.ces.census.gov/j2j/flow
total = data.frame
for(file in list.files(path="J2J")){
  if(file != "Geo Names.txt"){
    print(file)
    dfile = read.csv(paste("J2J\\",file,sep=""))
    dfile = dfile[dfile$geography == dfile$geography_orig,]
    if(length(total)==1){
      total = dfile
    } else{
      total = rbind(total, dfile)
    }
  }

  
  
}


geoNames = read.delim("J2J\\Geo Names.txt", header=F)
geoNames = data.frame(geoNames[!(geoNames$V1 %in% c("Origin","Destination")),])
colnames(geoNames) = c("label")
geoNames$code = as.numeric(str_sub(geoNames$label, 1,5))
geoNames$name = str_sub(geoNames$label, 6)
total = merge(total, geoNames[,c(2,3)], by.x="geography", by.y="code", all=T)
names(total)[names(total)=="name"] = "metro"
total$state = str_sub(total$metro, -2)
total$state2 = str_sub(total$metro, -5,-4)
total$state2[str_sub(total$metro,-3,-3)!="-"]=NA
cols = c(1, 15, 16, (25:36), (49:51))
total = total[,cols]
total$num_states = 2 - as.numeric(is.na(total$state2))
total$is_metro = as.numeric(str_sub(total$metro, end=7) != " Not in")

write.csv(total, "TotalJ2J.csv", row.names=F)

total = read.csv("TotalJ2J.csv")


```

```{r}
# Alternate J2J: from MSA, industry of interest to anywhere, any industry
total = read.csv("J2J_2.csv")
total = total[total$industry_orig == "44-45" & total$education == "E0",]
cols = c(15,16,19,25,26)
total = total[,cols]

geoNames = read.delim("J2J\\Geo Names.txt", header=F)
geoNames = data.frame(geoNames[!(geoNames$V1 %in% c("Origin","Destination")),])
colnames(geoNames) = c("label")
geoNames$code = as.numeric(str_sub(geoNames$label, 1,5))
geoNames$name = str_sub(geoNames$label, 6)

total = merge(total, geoNames[,c(2,3)], by.x="geography_orig", by.y="code", all=T)
colnames(total)[colnames(total)=="geography_orig"] = "geography"

names(total)[names(total)=="name"] = "metro"
total$state = str_sub(total$metro, -2)
total$state2 = str_sub(total$metro, -5,-4)
total$state2[str_sub(total$metro,-3,-3)!="-"]=NA
total$num_states = 2 - as.numeric(is.na(total$state2))
total$is_metro = as.numeric(str_sub(total$metro, end=7) != " Not in")

write.csv(total, "TotalJ2J_2.csv", row.names=F)
```

```{r}
# Alternate J2J: like above, but also includes food industry
total = read.csv("J2J_2.csv")
#total = total[total$education == "E0",]
cols = c(12,15,16,19,21,25,26)
total = total[,cols]

geoNames = read.delim("J2J\\Geo Names.txt", header=F)
geoNames = data.frame(geoNames[!(geoNames$V1 %in% c("Origin","Destination")),])
colnames(geoNames) = c("label")
geoNames$code = as.numeric(str_sub(geoNames$label, 1,5))
geoNames$name = str_sub(geoNames$label, 6)

total = merge(total, geoNames[,c(2,3)], by.x="geography_orig", by.y="code", all=T)
colnames(total)[colnames(total)=="geography_orig"] = "geography"
colnames(total)[colnames(total)=="industry_orig"] = "industry"

names(total)[names(total)=="name"] = "metro"
total$state = str_sub(total$metro, -2)
total$state2 = str_sub(total$metro, -5,-4)
total$state2[str_sub(total$metro,-3,-3)!="-"]=NA
total$num_states = 2 - as.numeric(is.na(total$state2))
total$is_metro = as.numeric(str_sub(total$metro, end=7) != " Not in")

write.csv(total, "TotalJ2J_3.csv", row.names=F)
```

```{r}
# Alternate J2J: like above, but all industries and age instead of education
total = read.csv("J2J_3.csv")
cols = c(9,15,16,19,21,(25:30))
total = total[,cols]

geoNames = read.delim("J2J\\Geo Names.txt", header=F)
geoNames = data.frame(geoNames[!(geoNames$V1 %in% c("Origin","Destination")),])
colnames(geoNames) = c("label")
geoNames$code = as.numeric(str_sub(geoNames$label, 1,5))
geoNames$name = str_sub(geoNames$label, 6)

total = merge(total, geoNames[,c(2,3)], by.x="geography_orig", by.y="code", all=T)
colnames(total)[colnames(total)=="geography_orig"] = "geography"
colnames(total)[colnames(total)=="industry_orig"] = "industry"

names(total)[names(total)=="name"] = "metro"
total$state = str_sub(total$metro, -2)
total$state2 = str_sub(total$metro, -5,-4)
total$state2[str_sub(total$metro,-3,-3)!="-"]=NA
total$num_states = 2 - as.numeric(is.na(total$state2))
total$is_metro = as.numeric(str_sub(total$metro, end=7) != " Not in")

write.csv(total, "TotalJ2J_4.csv", row.names=F)
```


```{r}
# Employment: US Census Bureau - https://ledextract.ces.census.gov/j2j/emp
total = read.csv("TotalJ2J_4.csv")
library(dplyr)
library(plyr)

emp = read.csv("Metro Employment All.csv")
cols = c(4,6,9, 15, 16, (18:24))
emp = emp[,cols]

emp_A00 = emp[emp$agegrp == "A00", colnames(emp)!="agegrp"]
emp_A01 = emp[emp$agegrp == "A01", colnames(emp)!="agegrp"]
emp_A02 = emp[emp$agegrp == "A02", colnames(emp)!="agegrp"]

colnames(emp_A00)[-(1:4)] = paste(colnames(emp_A00)[-(1:4)],"A00",sep="_")

emp_comp_01 = merge(emp_A00,emp_A01,all.y=T,  by=c("geography","industry","year","quarter"))
emp_comp_02 = merge(emp_A00,emp_A02,all.y=T,  by=c("geography","industry","year","quarter"))

for(i in (12:18)){
  col = colnames(emp_comp_01)[i]
  j = i - 7
  emp_comp_01[[paste(col,"prop",sep="_")]] = emp_comp_01[[i]] / emp_comp_01[[j]]
}
for(i in (12:18)){
  col = colnames(emp_comp_02)[i]
  j = i - 7
  emp_comp_02[[paste(col,"prop",sep="_")]] = emp_comp_02[[i]] / emp_comp_02[[j]]
}

emp_A00$agegrp = "A00"

emp_comp_01$agegrp = "A01"
emp_comp_02$agegrp = "A02"
emp_comp_01 = emp_comp_01[-(5:11)]
emp_comp_02 = emp_comp_02[-(5:11)]
emp_A00 = emp[emp$agegrp == "A00",]

emp = rbind.fill(emp_A00,emp_comp_01,emp_comp_02)


# Lagged dependent variables:
lagQuarter = function(data){
  data$quarter = data$quarter + 1
  data$year[data$quarter == 5] = data$year[data$quarter == 5] + 1
  data$quarter[data$quarter == 5] = 1
  return(data)
}
emp_1 = lagQuarter(emp)
colnames(emp_1)[-(1:5)] = paste(colnames(emp_1)[-(1:5)], "_1", sep="")
emp = merge(emp, emp_1, all.x=T)



total = merge(total, emp, by=c("geography", "year", "quarter","agegrp","industry"))
#total$conc = total$J2J / total$MainE
#total$concS = total$J2JS / total$MainES
# stable has more missing values

write.csv(total, "Concentration.csv", row.names=F)
```


```{r}
# QCEW combination: downloadable files by industry
total = data.frame()
files = list.files(path="QCEW")
for(file in files){
  print(file)
  dfile = read.csv(paste("QCEW\\",file,sep=""))
  if(dim(total)[1]==0){
    total = dfile
    cols = colnames(dfile)
  } else{
    colnames(dfile) = cols
    total = rbind(total, dfile)
    }
}

total = total[total$agglvl_code %in% c(40,44),]
write.csv(total,"QCEW Combined.csv", row.names=F)



total = read.csv("QCEW Combined.csv")
library(stringr)
cols = c(1,3,6,7,9,11,(14:21),(23:30))
#15,16,17
#24,25,26
total = total[,cols]
total$area_fips = str_sub(total$area_fips,2)
total$area_fips = as.numeric(total$area_fips)
colnames(total)[(1:4)] = c("geography","industry","year","quarter")


totalMarket = total[total$industry=="10",]
total = total[total$industry!="10",]
```


```{r}
conc = read.csv("Concentration.csv")
colnames(conc)[(2:3)] = c("year","quarter")
conc$geography = conc$geography %/% 10

combined = merge(total, conc, by=c("geography","year","quarter","industry"))
```

```{r}
#MW
#https://www.kaggle.com/datasets/lislejoem/us-minimum-wage-by-state-from-1968-to-2017
library(plyr)
mw = read.csv("Minimum Wage Data.csv")
abbr = read.delim2("State Abbr.txt", header=F)
mw$StateAbbr = mapvalues(toupper(mw$State),abbr$V1, abbr$V2, warn_missing = F)
mw = mw[,colnames(mw) %in% c("Year","StateAbbr","Effective.Minimum.Wage")]
colnames(mw) = c("year","minimum_wage","state")
combined = left_join(combined, mw, by=c("year","state"))

```





```{r}
# QCEW Repeat for all industries:
cols = c(1,3,4,(7:22))
colnames(totalMarket)[(7:22)] = paste("TOTAL_",colnames(totalMarket)[(7:22)],sep="")
totalMarket = totalMarket[,cols]

combined = merge(combined, totalMarket, by=c("geography","year","quarter"))


```

```{r}
# Separations: US Census Bureau - J2J Separations
sep = read.csv("Separations All.csv")
cols = c(4,6,9,15,16,(18:28))
sep = sep[,cols]
sep$geography = sep$geography %/% 10
combined = merge(combined, sep, by=c("geography","year","quarter","industry","agegrp"))

write.csv(combined, "ConcData.csv", row.names=F)
```

```{r}
library(ipumsr)
library(dplyr)
library(plyr)
ddi = read_ipums_ddi("cps_00003.xml")
msa = read_ipums_micro(ddi)
msa = msa[!duplicated(msa[c(1,3,12)]),]
msa = msa %>% group_by(YEAR,METFIPS) %>% slice_min(order_by = MONTH)
msa$size = msa$CBSASZ
msa$size[is.na(msa$size)] = msa$MSACMSZ
msa$METFIPS = msa$METFIPS %/% 10
msa = msa[c(1,12,26)]
colnames(msa) = c("year","geography","metro_size")

combined = read.csv("ConcData.csv")
combined = merge(combined, msa, by=c("year","geography"))
write.csv(combined, "ConcData.csv", row.names=F)
```


```{r}
combined = read.csv("ConcData.csv")
library(readxl)
library(stringr)
mwState = read_excel("VZ_state_quarterly.xlsx")
mwState$year = as.numeric(str_sub(mwState$`Quarterly Date`,1,4))
mwState$quarter = as.numeric(str_sub(mwState$`Quarterly Date`,6,6))
mwState$effective = pmax(mwState$`Quarterly Federal Minimum`, mwState$`Quarterly State Minimum`)
mwState = mwState[c(3,11,12,13)]
colnames(mwState)[1] = "state"
combined = merge(combined, mwState, all.x=T)
colnames(combined)[colnames(combined) == "minimum_wage"] = "effective1"
combined$minimum_wage = combined$effective1
combined$minimum_wage[!is.na(combined$effective)] = combined$effective[!is.na(combined$effective)]
combined$quarterlyMW = as.numeric(!is.na(combined$effective))

write.csv(combined, "ConcData.csv", row.names=F)

# 
# mwSub = read_excel("VZ_substate_quarterly.xlsx")
# mwSub$year = as.numeric(str_sub(mwSub$`Quarterly Date`,1,4))
# mwSub$quarter = as.numeric(str_sub(mwSub$`Quarterly Date`,6,6))
# mwSub = mwSub[mwSub$`Local > State min wage`==1,c(3,4,6,10,11)]
# 
# countyMSA = read.csv("county-msa.csv")
# countyMSA = countyMSA[c(2,4)]
# countyMSA = countyMSA[countyMSA$MSA.Title != "",]
# countyMSA = countyMSA[!duplicated(countyMSA$MSA.Title),]
# countyMSA$County.Title[countyMSA$County.Title == ""] = "a,b"
# mid = unlist(strsplit(countyMSA$County.Title,", "))


```

```{r}
combined = read.csv("ConcData.csv")
smallData = combined[c((1:6),16,27,33,34,37,58,51,64,65,68,71,84,91,93,94)]
write.csv(smallData, "SmallData.csv",row.names=F)
```

*Drop self-employed
drop if (class==5 | class==6) & year<=1993
drop if (class94==6 | class94==7) & year>=1994

drop class class94


```{r}
#cps
# industry: retail is 580-691
# food: 762, 770, 611, 122

rm(list=ls())
library(ipumsr)
library(stringr)
library(dplyr)
library(plyr)
ddi = read_ipums_ddi("cps_00009.xml")
data = read_ipums_micro(ddi)
data = filter(data, !CLASSWKR %in% c(10,13,14))
data$employed = as.numeric(data$EMPSTAT %in% c(10,12))
data$HOURWAGE[data$employed == 0] = 0
data = filter(data, HOURWAGE < 999.99)
```


```{r}
stateFIPS = read.csv("stateFIPS.csv")
stateFIPS = stateFIPS %>% filter(!(FIPS.Code %in% c(72,78)))
stateFIPS$FIPS.Code = as.numeric(stateFIPS$FIPS.Code)
data$STATEFIP = as.numeric(data$STATEFIP)
data$STATE = mapvalues(data$STATEFIP, stateFIPS$FIPS.Code, stateFIPS$Postal.Abbr)
#data$METFIPS[data$METFIPS == 99998] = as.numeric(paste(data$STATEFIP[data$METFIPS == 99998], 999, sep=""))
data$QUARTER = ceiling(data$MONTH/3)
```


```{r}

library(readxl)
library(stringr)
library(plm)
# need to define events
wage_threshold = 0.005

cpi = read.csv("CPIAUCSL.csv")
dates = str_split(cpi$DATE,"-")
cpi$YEAR = as.numeric(sapply(dates,"[[",1))
cpi$MONTH = as.numeric(sapply(dates,"[[",2))
cpiBase = cpi$CPIAUCSL[cpi$YEAR==2014 & cpi$MONTH == 1]
cpi$CPI_FACTOR = cpi$CPIAUCSL / cpiBase
cpi = cpi[!colnames(cpi) %in% c("DATE","CPIAUCSL")]
cpiQuarter = filter(cpi, MONTH %% 3 == 0)
cpiQuarter$MONTH = cpiQuarter$MONTH / 3
colnames(cpiQuarter)[colnames(cpiQuarter) == "MONTH"] = 'QUARTER'

mwState = read_excel("VZ_state_quarterly.xlsx")
mwState$YEAR = as.numeric(str_sub(mwState$`Quarterly Date`,1,4))
mwState$QUARTER = as.numeric(str_sub(mwState$`Quarterly Date`,6,6))
mwState = merge(mwState, cpiQuarter)

mwState$MW = pmax(mwState$`Quarterly Federal Minimum`, mwState$`Quarterly State Minimum`)
mwState = mwState[c(1,2,3,5,11,12,13,14)]
colnames(mwState)[4] = "STATE"
colnames(mwState)[5]="MW_FED"
colnames(mwState)[3] = "STATEFIP"
colnames(mwState)[6] = "MW_STATE"
mwState$CHANGE = 0
mwState$DIST_F = -9
mwState$DIST_B = -9
mwState$NextMW = NA
mwState$LastChange = 0
mwState$LastChangePct = 0
for(state in unique(mwState$STATE)){
  filt = mwState$STATE == state
  mwState$CHANGE[filt] = c(0, diff(mwState$MW[filt])) / mwState$CPI_FACTOR[filt]
  mwState$CHANGE_PCT[filt] = c(0, diff(mwState$MW[filt])) / c(1, mwState$MW[filt][-length(mwState$MW[filt])])
  mwState$DIST_F[filt & mwState$CHANGE_PCT >=wage_threshold] = 0
  mwState$DIST_B[filt & mwState$CHANGE_PCT >=wage_threshold] = 0
  
  
  
  d = sum(filt)
  count = 0
  for(i in (1:d)){
    if(mwState$DIST_F[filt][i] == 0){count = 1}
    else if(count > 0){mwState$DIST_F[filt][i] = count; count = count + 1}
    if(mwState$DIST_F[filt][i] == 0){
      mwState$LastChangePct[filt][i] = mwState$CHANGE_PCT[filt][i]
      mwState$LastChange[filt][i] = mwState$CHANGE[filt][i]
    }
    else if(i>1){
      mwState$LastChangePct[filt][i] = mwState$LastChangePct[filt][i-1]
      mwState$LastChange[filt][i] = mwState$LastChange[filt][i-1]
    }
    
  }
  count = 0
  nextMW = NA
  for(j in (1:d)){
    i = d + 1 - j
    if(mwState$DIST_B[filt][i] == 0){count = 1; nextMW = mwState$MW[filt][i]}
    else if(count > 0){mwState$DIST_B[filt][i] = count; mwState$NextMW[filt][i] = nextMW;count = count + 1}
  }
  
}
mwState$DIST_F[mwState$DIST_F == -9] = NA
mwState$DIST_F[mwState$DIST_F > 15] = NA
mwState$DIST_B[mwState$DIST_B == -9] = NA
mwState$DIST_B[mwState$DIST_B >12] = NA

# Fed changes:
mwState$CHANGE_FED = 0
mwState$DIST_F_FED = -9
mwState$DIST_B_FED = -9
mwState$NextMW_FED = NA
for(state in unique(mwState$STATE)){
  mwState$CHANGE_FED[mwState$STATE == state] = c(0, diff(mwState$MW_FED[mwState$STATE == state])) / mwState$CPI_FACTOR[mwState$STATE == state]
  mwState$CHANGE_FED[mwState$STATE == state & mwState$CHANGE_FED != 0] = (mwState$CHANGE_FED - mwState$CHANGE)[mwState$STATE == state & mwState$CHANGE_FED != 0]
  mwState$DIST_F_FED[mwState$STATE == state & mwState$CHANGE_FED >=wage_threshold] = 0
  mwState$DIST_B_FED[mwState$STATE == state & mwState$CHANGE_FED >= wage_threshold] = 0

  d = sum(mwState$STATE == state)
  count = 0
  for(i in (1:d)){
    if(mwState$DIST_F_FED[mwState$STATE == state][i] == 0){count = 1}
    else if(count > 0){mwState$DIST_F_FED[mwState$STATE == state][i] = count; count = count + 1}
  }
  count = 0
  nextMW = NA
  for(j in (1:d)){
    i = d + 1 - j
    if(mwState$DIST_B_FED[mwState$STATE == state][i] == 0){count = 1; nextMW = mwState$MW_FED[mwState$STATE == state][i]}
    else if(count > 0){mwState$DIST_B_FED[mwState$STATE == state][i] = count; mwState$NextMW_FED[mwState$STATE == state][i] = nextMW;count = count + 1}
  }

}

#small effective changes:
mwState$CHANGE = 0
mwState$DIST_F_EFF = -9
mwState$DIST_B_EFF = -9
mwState$NextMW = NA
for(state in unique(mwState$STATE)){
  mwState$CHANGE[mwState$STATE == state] = c(0, diff(mwState$MW[mwState$STATE == state])) / mwState$CPI_FACTOR[mwState$STATE == state]
  mwState$DIST_F_EFF[mwState$STATE == state & mwState$CHANGE < wage_threshold & mwState$CHANGE > 0] = 0
  mwState$DIST_B_EFF[mwState$STATE == state & mwState$CHANGE < wage_threshold & mwState$CHANGE > 0] = 0

  d = sum(mwState$STATE == state)
  count = 0
  for(i in (1:d)){
    if(mwState$DIST_F_EFF[mwState$STATE == state][i] == 0){count = 1}
    else if(count > 0){mwState$DIST_F_EFF[mwState$STATE == state][i] = count; count = count + 1}
  }
  count = 0
  nextMW = NA
  for(j in (1:d)){
    i = d + 1 - j
    if(mwState$DIST_B_EFF[mwState$STATE == state][i] == 0){count = 1; nextMW = mwState$MW[mwState$STATE == state][i]}
    else if(count > 0){mwState$DIST_B_EFF[mwState$STATE == state][i] = count; mwState$NextMW[mwState$STATE == state][i] = nextMW;count = count + 1}
  }

}
mwState$DIST_F_EFF[mwState$DIST_F_EFF == -9] = NA
mwState$DIST_F_EFF[mwState$DIST_F_EFF > 15] = NA
mwState$DIST_B_EFF[mwState$DIST_B_EFF == -9] = NA
mwState$DIST_B_EFF[mwState$DIST_B_EFF >12] = NA

mwState$DIST_EFF = mwState$DIST_F_EFF
mwState$DIST_EFF[!is.na(mwState$DIST_B_EFF) & is.na(mwState$DIST_F_EFF)] = - mwState$DIST_B_EFF[!is.na(mwState$DIST_B_EFF) & is.na(mwState$DIST_F_EFF)]



mwState$DIST_F_FED[mwState$DIST_F_FED == -9] = NA
mwState$DIST_F_FED[mwState$DIST_F_FED > 15] = NA
mwState$DIST_B_FED[mwState$DIST_B_FED == -9] = NA
mwState$DIST_B_FED[mwState$DIST_B_FED >12] = NA

mwState$DIST_FED = mwState$DIST_F_FED
mwState$DIST_FED[!is.na(mwState$DIST_B_FED) & is.na(mwState$DIST_F_FED)] = - mwState$DIST_B_FED[!is.na(mwState$DIST_B_FED) & is.na(mwState$DIST_F_FED)]
mwState$NextMW_FED[mwState$DIST_FED > 0] = NA


mwState$DIST = mwState$DIST_F
mwState$DIST[!is.na(mwState$DIST_B) & is.na(mwState$DIST_F)] = - mwState$DIST_B[!is.na(mwState$DIST_B) & is.na(mwState$DIST_F)]
mwState$NextMW[mwState$DIST > 0] = NA
colnames(mwState)[colnames(mwState)=="CHANGE"] = "REAL_CHANGE"

mwState$DIST[is.na(mwState$DIST)] = 999
#mwState = mwState[c(1,2,3,7,8,9,12,15,22,23,24)]
#mwState = mwState[c(1,2,3,4,5,9,16,17,18)]
```


```{r}
data1 = data[(1:20000000),]
data = data[(20000001:dim(data)[1]),]

data1 = merge(data1, mwState)
#write.csv(data1, "temp1.csv",row.names=F)
#rm(data1)

data = merge(data, mwState)
#write.csv(data, "temp2.csv",row.names=F)

data = rbind(data,data1)
rm(data1)
```


```{r}
#data = data[!is.na(data$DIST),]
data$empW = data$employed * data$EARNWT
data$REF_WAGE = (data$HOURWAGE - data$MW) / data$CPI_FACTOR
data$REF_WAGE[!is.na(data$DIST)][data$DIST[!is.na(data$DIST)] < 0] = data$HOURWAGE - data$NextMW
data$UHRSWORKORG[data$UHRSWORKORG >= 998] = NA

data$WAGE_BIN = floor(data$REF_WAGE)
data$WAGE_BIN[data$WAGE_BIN > 20] = 20
data$WAGE_BIN[data$WAGE_BIN < -5] = -5

pop = aggregate(EARNWT ~ YEAR + STATEFIP + QUARTER, data=data, FUN=sum)
colnames(pop)[4] = "POPULATION"
totalHours = aggregate(EARNWT*employed*UHRSWORKORG ~ YEAR + STATEFIP + QUARTER, data=data, FUN=sum)
colnames(totalHours)[4] = "TOTAL_HOURS"
wageBinHours = aggregate(EARNWT*employed*UHRSWORKORG ~ YEAR + STATEFIP + QUARTER + WAGE_BIN, data=data, FUN=sum)
colnames(wageBinHours)[5] = "WAGE_BIN_HOURS"


data1 = aggregate(empW ~ YEAR + QUARTER + STATEFIP + WAGE_BIN, data=data, FUN=sum)

data1 = merge(data1, mwState)
data1 = merge(data1, pop)
data1 = merge(data1, totalHours,all.x=T)
data1 = merge(data1, wageBinHours,all.x=T)
data1$DIST_YEAR = floor(data1$DIST/4)
data1$DIST_EFF_YEAR = floor(data1$DIST_EFF/4)
data1$DIST_FED_YEAR = floor(data1$DIST_FED/4)
data1$EMP_RATE = data1$empW / data1$POPULATION
data1$AVG_HOURS = data1$WAGE_BIN_HOURS / data1$POPULATION
write.csv(data1, "EventDataQuarterPct.csv",row.names=F)
```












```{r}
sep = read.csv("EnSep Complete.csv")
sep = sep[c(4,6,9,15,16,18)]
colnames(sep) = c("METFIPS","INDUSTRY","AGEGRP","YEAR","QUARTER","ENSep")

ees = read.csv("EES Complete.csv")
ees = ees[c(9,15,16,19,21,25)]
colnames(ees) = c("AGEGRP","YEAR","QUARTER","METFIPS","INDUSTRY","EES")

conc = merge(sep,ees)
conc$COMPETITION = conc$EES / conc$ENSep
conc$COMPETITION[conc$COMPETITION == Inf] = max(conc$COMPETITION[!is.na(conc$COMPETITION) & conc$COMPETITION<Inf])

write.csv(conc, "Conc Complete.csv",row.names=F)
```




Alter with concentration below:

```{r}
rm(list=ls())
library(ipumsr)
library(stringr)
library(dplyr)
library(plyr)

conc = read.csv("Conc Complete.csv")
between = dplyr::between

industryMap = function(x){
  y = rep("00",length(x))
  y[between(x,10,32)]="11"
  y[between(x,40,50)]="21"
  y[between(x,450,470) | x==472]="22"
  y[x==60]=23
  y[between(x,100,392)]="31-33"
  y[between(x,500,571)]="42"
  y[between(x,580,691)]="44-45"
  y[between(x,400,432)]="48-49"
  y[between(x,440,442) | x==852]="51"
  y[between(x,700,711)] ="52"
  y[x==712]="53"
  y[x==841 | between(x,882,891) | x==893]="54"
  y[x==892]="55"
  y[x==471 | between(x,740,741)]="56"
  y[between(x,842,851) | between(x,860,861)]="61"
  y[between(x,812,840) | between(x,862,871)]="62"
  y[between(x,800,810) | x==872]="71"
  y[between(x,762,770)]="72"
  y[between(x,873,881) | between(x,721,732) | between(x,742,761) | between(x,771,791)]="81"
  y[between(x,900,932)]="92"
  return(y)
}

ageMap = function(x){
  y = rep("A00",length(x))
  y[between(x,14,18)] = "A01"
  y[between(x,19,21)]="A02"
  y[between(x,22,24)]="A03"
  y[between(x,25,34)]="A04"
  y[between(x,35,44)]="A05"
  y[between(x,45,54)]="A06"
  y[between(x,55,64)]="A07"
  y[between(x,65,99)]="A08"
  return(y)
}

fipsMap = function(x, statefips){
  y = rep(00,length(x))
  y[x %in% conc$METFIPS] = x[x%in% conc$METFIPS]
  y[! x %in% conc$METFIPS] = statefips[! x %in% conc$METFIPS]
  return(y)
}

```


```{r}
#cps

# industry: 
# retail is 580-691
# food: 761 - 770

ddi = read_ipums_ddi("cps_00009.xml")
data = read_ipums_micro(ddi)
data = filter(data, YEAR >= 2000 & AGE >= 14 & (YEAR > 2000 | MONTH > 6))
#data = filter(data, IND1990 > 0)



# Prepare data for merging with concentration:
stateFIPS = read.csv("stateFIPS.csv")
stateFIPS = stateFIPS %>% filter(!(FIPS.Code %in% c(72,78)))
stateFIPS$FIPS.Code = as.numeric(stateFIPS$FIPS.Code)
data$STATEFIP = as.numeric(data$STATEFIP)
data$STATE = mapvalues(data$STATEFIP, stateFIPS$FIPS.Code, stateFIPS$Postal.Abbr)
#data$METFIPS[!data$METFIPS %in% unique(conc$METFIPS)]=99998
data$METFIPS[data$METFIPS == 99998] = as.numeric(paste0(data$STATEFIP[data$METFIPS == 99998], 999))
data$QUARTER = ceiling(data$MONTH/3)


pop = aggregate(EARNWT ~ YEAR + STATEFIP + QUARTER, data=data, FUN=sum)
colnames(pop)[4] = "POPULATION"

data = filter(data, !CLASSWKR %in% c(10,13,14))
data$employed = as.numeric(data$EMPSTAT %in% c(10,12))
data$HOURWAGE[data$employed == 0] = 0
data = filter(data, HOURWAGE < 999.99)

data = merge(data, pop, all.x=T)

# data$INDUSTRY = industryMap(data$IND1990)
# data$INDUSTRY[is.na(data$INDUSTRY)] = "NA"
#data = merge(data, conc, all.x=T)
#data = filter(data, !is.na(COMPETITION))

data$AGEGRP = ageMap(as.numeric(data$AGE))
data$INDUSTRY = industryMap(as.numeric(data$IND1990))
data$METFIPS = fipsMap(data$METFIPS, data$STATEFIP)

data = merge(data, conc, all.x=T)
data$METFIPS[is.na(data$COMPETITION)] = 0
data[is.na(data$COMPETITION),] = merge(data[is.na(data$COMPETITION),(1:17)],filter(conc,METFIPS==0), all.x=T)


# data$COMPETITION[data$COMPETITION=="NA"] = merge(data[data$COMPETITION=="NA",colnames(data)!="COMPETITION"], metroConc, all.x=T)$COMPETITION

probs = (0:5)/5
compQ = quantile(data$COMPETITION,probs=probs)
data$COMP_Q = 0
for(i in (1:(length(compQ)-1))){
  data$COMP_Q[between(data$COMPETITION,compQ[i],compQ[i+1])] = probs[i]
}

subPop = aggregate(EARNWT ~ YEAR + STATEFIP + QUARTER + COMP_Q, data=data, FUN=sum)
colnames(subPop)[5] = "POPULATION_SUB"
data= merge(data, subPop, all.x=T)
```



```{r}

library(readxl)
library(stringr)
library(plm)
# need to define events
wage_threshold = 0.2

cpi = read.csv("CPIAUCSL.csv")
dates = str_split(cpi$DATE,"-")
cpi$YEAR = as.numeric(sapply(dates,"[[",1))
cpi$MONTH = as.numeric(sapply(dates,"[[",2))
cpiBase = cpi$CPIAUCSL[cpi$YEAR==2014 & cpi$MONTH == 1]
cpi$CPI_FACTOR = cpi$CPIAUCSL / cpiBase
cpi = cpi[!colnames(cpi) %in% c("DATE","CPIAUCSL")]
cpiQuarter = filter(cpi, MONTH %% 3 == 0)
cpiQuarter$MONTH = cpiQuarter$MONTH / 3
colnames(cpiQuarter)[colnames(cpiQuarter) == "MONTH"] = 'QUARTER'

mwState = read_excel("VZ_state_quarterly.xlsx")
mwState$YEAR = as.numeric(str_sub(mwState$`Quarterly Date`,1,4))
mwState$QUARTER = as.numeric(str_sub(mwState$`Quarterly Date`,6,6))
mwState = merge(mwState, cpiQuarter)
mwState = filter(mwState, YEAR > 1995)

mwState$MW = pmax(mwState$`Quarterly Federal Minimum`, mwState$`Quarterly State Minimum`)
mwState = mwState[c(1,2,3,5,11,12,13,14)]
colnames(mwState)[4] = "STATE"
colnames(mwState)[5]="MW_FED"
colnames(mwState)[3] = "STATEFIP"
colnames(mwState)[6] = "MW_STATE"
mwState$CHANGE = 0
mwState$DIST_F = -9
mwState$DIST_B = -9
mwState$NextMW = NA
mwState$LastChange = 0
mwState$LastChangePct = 0
for(state in unique(mwState$STATE)){
  mwState$CHANGE[mwState$STATE == state] = c(0, diff(mwState$MW[mwState$STATE == state])) / mwState$CPI_FACTOR[mwState$STATE == state]
  mwState$CHANGE_PCT[mwState$STATE == state] = c(0, diff(mwState$MW[mwState$STATE == state])) / c(1, mwState$MW[mwState$STATE==state][-length(mwState$MW[mwState$STATE==state])])
  mwState$DIST_F[mwState$STATE == state & mwState$CHANGE >=wage_threshold] = 0
  mwState$DIST_B[mwState$STATE == state & mwState$CHANGE >=wage_threshold] = 0
  
  filt = mwState$STATE == state
  
  d = sum(filt)
  count = 0
  for(i in (1:d)){
    if(mwState$DIST_F[filt][i] == 0){count = 1}
    else if(count > 0){mwState$DIST_F[filt][i] = count; count = count + 1}
    if(mwState$DIST_F[filt][i] == 0){
      mwState$LastChangePct[filt][i] = mwState$CHANGE_PCT[filt][i]
      mwState$LastChange[filt][i] = mwState$CHANGE[filt][i]
    }
    else if(i>1){
      mwState$LastChangePct[filt][i] = mwState$LastChangePct[filt][i-1]
      mwState$LastChange[filt][i] = mwState$LastChange[filt][i-1]
    }
    
  }
  count = 0
  nextMW = NA
  for(j in (1:d)){
    i = d + 1 - j
    if(mwState$DIST_B[filt][i] == 0){count = 1; nextMW = mwState$MW[filt][i]}
    else if(count > 0){mwState$DIST_B[filt][i] = count; mwState$NextMW[filt][i] = nextMW;count = count + 1}
  }
  
}
mwState$DIST_F[mwState$DIST_F == -9] = NA
mwState$DIST_F[mwState$DIST_F > 15] = NA
mwState$DIST_B[mwState$DIST_B == -9] = NA
mwState$DIST_B[mwState$DIST_B >12] = NA

mwState$DIST = mwState$DIST_F
mwState$DIST[!is.na(mwState$DIST_B) & is.na(mwState$DIST_F)] = - mwState$DIST_B[!is.na(mwState$DIST_B) & is.na(mwState$DIST_F)]
mwState$NextMW[mwState$DIST > 0] = NA
colnames(mwState)[colnames(mwState)=="CHANGE"] = "REAL_CHANGE"

mwState$DIST[is.na(mwState$DIST)] = 999
mwState = mwState[c(1,2,3,7,8,9,12,13,14,15,16)]

```



```{r}
data = merge(data, mwState)
data$empW = data$employed * data$EARNWT
data$REF_WAGE = (data$HOURWAGE - data$MW) / data$CPI_FACTOR
data$REF_WAGE[!is.na(data$DIST)][data$DIST[!is.na(data$DIST)] < 0] = (data$HOURWAGE - data$NextMW)[!is.na(data$DIST)][data$DIST[!is.na(data$DIST)] < 0]
data$UHRSWORKORG[data$UHRSWORKORG >= 998] = NA

data$WAGE_BIN = floor(data$REF_WAGE)
data$WAGE_BIN[data$WAGE_BIN > 20] = 20
data$WAGE_BIN[data$WAGE_BIN < -5] = -5

# data2 = aggregate(empW ~ YEAR + QUARTER + STATEFIP + WAGE_BIN + COMP_Q, data=data, FUN=sum)
# library(tidyr)
# # Balance data set:
# data2 = complete(data2, YEAR, QUARTER, STATEFIP, WAGE_BIN, COMP_Q, fill=list(empW=0))
# data2 = filter(data2, (YEAR > 2000) | (QUARTER > 2))
# data2 = merge(data2, pop, all.x=T)
# data2 = merge(data2, subPop, all.x=T)
# data2$POPULATION_SUB[is.na(data2$POPULATION_SUB) | data2$POPULATION_SUB==0] = 1
# data1 = data2
write.csv(data, "IndividualDataConc.csv",row.names=F)

data1 = aggregate(empW ~ YEAR + QUARTER + STATEFIP + WAGE_BIN + COMP_Q + POPULATION + POPULATION_SUB, data=data, FUN=sum)
data1 = merge(data1, mwState)
data1$DIST_YEAR = floor(data1$DIST/4)
data1$EMP_RATE = data1$empW / data1$POPULATION
data1$EMP_RATE_SUB = data1$empW / data1$POPULATION_SUB
data1$EMP_RATE_SUB[is.na(data1$EMP_RATE_SUB)] = 0
write.csv(data1, "EventDataQuarterConcFifths.csv",row.names=F)
```



```{r}
# need to attach MW, concentration, other controls?


# merge conc and data by: geography, quarter, year, industry, 

```












New event definitions:

```{r}
rm(list=ls())
library(ipumsr)
library(stringr)
library(dplyr)
library(plyr)

conc = read.csv("Conc Complete.csv")
between = dplyr::between

industryMap = function(x){
  y = rep("00",length(x))
  y[between(x,10,32)]="11"
  y[between(x,40,50)]="21"
  y[between(x,450,470) | x==472]="22"
  y[x==60]=23
  y[between(x,100,392)]="31-33"
  y[between(x,500,571)]="42"
  y[between(x,580,691)]="44-45"
  y[between(x,400,432)]="48-49"
  y[between(x,440,442) | x==852]="51"
  y[between(x,700,711)] ="52"
  y[x==712]="53"
  y[x==841 | between(x,882,891) | x==893]="54"
  y[x==892]="55"
  y[x==471 | between(x,740,741)]="56"
  y[between(x,842,851) | between(x,860,861)]="61"
  y[between(x,812,840) | between(x,862,871)]="62"
  y[between(x,800,810) | x==872]="71"
  y[between(x,762,770)]="72"
  y[between(x,873,881) | between(x,721,732) | between(x,742,761) | between(x,771,791)]="81"
  y[between(x,900,932)]="92"
  return(y)
}

ageMap = function(x){
  y = rep("A00",length(x))
  y[between(x,14,18)] = "A01"
  y[between(x,19,21)]="A02"
  y[between(x,22,24)]="A03"
  y[between(x,25,34)]="A04"
  y[between(x,35,44)]="A05"
  y[between(x,45,54)]="A06"
  y[between(x,55,64)]="A07"
  y[between(x,65,99)]="A08"
  return(y)
}

fipsMap = function(x, statefips){
  y = rep(00,length(x))
  y[x %in% conc$METFIPS] = x[x%in% conc$METFIPS]
  y[! x %in% conc$METFIPS] = statefips[! x %in% conc$METFIPS]
  return(y)
}

```


```{r}
#cps

# industry: 
# retail is 580-691
# food: 761 - 770

ddi = read_ipums_ddi("cps_00009.xml")
data = read_ipums_micro(ddi)
#data = filter(data, YEAR >= 2000 & AGE >= 14 & (YEAR > 2000 | MONTH > 6))
data = filter(data, YEAR >= 1996 & AGE >= 14)
#data = filter(data, IND1990 > 0)



# Prepare data for merging with concentration:
stateFIPS = read.csv("stateFIPS.csv")
stateFIPS = stateFIPS %>% filter(!(FIPS.Code %in% c(72,78)))
stateFIPS$FIPS.Code = as.numeric(stateFIPS$FIPS.Code)
data$STATEFIP = as.numeric(data$STATEFIP)
data$STATE = mapvalues(data$STATEFIP, stateFIPS$FIPS.Code, stateFIPS$Postal.Abbr)
#data$METFIPS[!data$METFIPS %in% unique(conc$METFIPS)]=99998
data$METFIPS[data$METFIPS == 99998] = as.numeric(paste0(data$STATEFIP[data$METFIPS == 99998], 999))
data$QUARTER = ceiling(data$MONTH/3)


pop = aggregate(EARNWT ~ YEAR + STATEFIP + QUARTER, data=data, FUN=sum)
colnames(pop)[4] = "POPULATION"

data = filter(data, !CLASSWKR %in% c(10,13,14))
data$employed = as.numeric(data$EMPSTAT %in% c(10,12))
data$HOURWAGE[data$employed == 0] = 0
data = filter(data, HOURWAGE < 999.99)

data = merge(data, pop, all.x=T)

# data$INDUSTRY = industryMap(data$IND1990)
# data$INDUSTRY[is.na(data$INDUSTRY)] = "NA"
#data = merge(data, conc, all.x=T)
#data = filter(data, !is.na(COMPETITION))

data$AGEGRP = ageMap(as.numeric(data$AGE))
data$INDUSTRY = industryMap(as.numeric(data$IND1990))
data$METFIPS = fipsMap(data$METFIPS, data$STATEFIP)

data = merge(data, conc, all.x=T)
data$METFIPS[is.na(data$COMPETITION)] = 0
data[is.na(data$COMPETITION),] = merge(data[is.na(data$COMPETITION),(1:17)],filter(conc,METFIPS==0), all.x=T)


# data$COMPETITION[data$COMPETITION=="NA"] = merge(data[data$COMPETITION=="NA",colnames(data)!="COMPETITION"], metroConc, all.x=T)$COMPETITION

#probs = (0:5)/5
probs = (0:10)/10
compQ = quantile(data$COMPETITION,probs=probs, na.rm=T)
data$COMP_Q = 0
for(i in (1:(length(compQ)-1))){
  data$COMP_Q[between(data$COMPETITION,compQ[i],compQ[i+1])] = probs[i]
}

subPop = aggregate(EARNWT ~ YEAR + STATEFIP + QUARTER + COMP_Q, data=data, FUN=sum)
colnames(subPop)[5] = "POPULATION_SUB"
data= merge(data, subPop, all.x=T)


```


Change CPI base 2014-->2016, wage_threshold 0.2-->0.25, limit to events with no events 3 years before or 4 years after
```{r}

library(readxl)
library(stringr)
library(plm)
# need to define events
wage_threshold = 0.25

cpi = read.csv("CPIAUCSL.csv")
dates = str_split(cpi$DATE,"-")
cpi$YEAR = as.numeric(sapply(dates,"[[",1))
cpi$MONTH = as.numeric(sapply(dates,"[[",2))
cpiBase = cpi$CPIAUCSL[cpi$YEAR==2016 & cpi$MONTH == 1]
cpi$CPI_FACTOR = cpi$CPIAUCSL / cpiBase
cpi = cpi[!colnames(cpi) %in% c("DATE","CPIAUCSL")]
cpiQuarter = filter(cpi, MONTH %% 3 == 0)
cpiQuarter$MONTH = cpiQuarter$MONTH / 3
colnames(cpiQuarter)[colnames(cpiQuarter) == "MONTH"] = 'QUARTER'

mwState = read_excel("VZ_state_quarterly.xlsx")
mwState$YEAR = as.numeric(str_sub(mwState$`Quarterly Date`,1,4))
mwState$QUARTER = as.numeric(str_sub(mwState$`Quarterly Date`,6,6))
mwState = merge(mwState, cpiQuarter)
mwState = filter(mwState, YEAR > 1995)

mwState$MW = pmax(mwState$`Quarterly Federal Minimum`, mwState$`Quarterly State Minimum`)
mwState = mwState[c(1,2,3,5,11,12,13,14)]
colnames(mwState)[4] = "STATE"
colnames(mwState)[5]="MW_FED"
colnames(mwState)[3] = "STATEFIP"
colnames(mwState)[6] = "MW_STATE"

# sufficient bind:
stateBind = merge(mwState, filter(data, HOURWAGE>0), all.x=T)
stateBind$Bind = as.numeric(stateBind$HOURWAGE < stateBind$MW)
stateBind$Bind[is.na(stateBind$Bind)] = 0
stateBind = aggregate(Bind ~ YEAR + QUARTER + STATEFIP, data=stateBind, FUN=mean)
mwState = merge(mwState, stateBind)

mwState$BindBefore = NA
mwState$CHANGE = 0
mwState$EVENT = 0
mwState$DIST_F = -9
mwState$DIST_B = -9
mwState$NextMW = NA
mwState$LastChange = 0
mwState$LastChangePct = 0
for(state in unique(mwState$STATE)){
  filt = mwState$STATE == state
  d = sum(filt)
  mwState$CHANGE[filt] = c(0, diff(mwState$MW[filt])) / mwState$CPI_FACTOR[filt]
  mwState$CHANGE_PCT[filt] = c(0, diff(mwState$MW[filt])) / c(1, mwState$MW[filt][-length(mwState$MW[filt])])
  mwState$BindBefore[filt] = c(NA, mwState$Bind[filt][-d])

  
  
  # sufficient space between events:
  mwState$EVENT[filt & mwState$CHANGE >=wage_threshold & mwState$BindBefore >= 0.02] = 1
  for(i in (1:d)){
    if(mwState$EVENT[filt][i]){
      start = max(1,i-12)
      end = min(d,i+15)
      check = mwState$EVENT[filt][(start:end)]
      if(sum(check)>1){mwState$EVENT[filt][i]=2}
    }
  }
  mwState$EVENT[filt][mwState$EVENT[filt]==2] = 0
  
  
  mwState$DIST_F[filt & mwState$EVENT] = 0
  mwState$DIST_B[filt & mwState$EVENT] = 0
  
  count = 0
  for(i in (1:d)){
    if(mwState$DIST_F[filt][i] == 0){count = 1}
    else if(count > 0){mwState$DIST_F[filt][i] = count; count = count + 1}
    if(mwState$DIST_F[filt][i] == 0){
      mwState$LastChangePct[filt][i] = mwState$CHANGE_PCT[filt][i]
      mwState$LastChange[filt][i] = mwState$CHANGE[filt][i]
    }
    else if(i>1){
      mwState$LastChangePct[filt][i] = mwState$LastChangePct[filt][i-1]
      mwState$LastChange[filt][i] = mwState$LastChange[filt][i-1]
    }
    
  }
  count = 0
  nextMW = NA
  for(j in (1:d)){
    i = d + 1 - j
    if(mwState$DIST_B[filt][i] == 0){count = 1; nextMW = mwState$MW[filt][i]}
    else if(count > 0){mwState$DIST_B[filt][i] = count; mwState$NextMW[filt][i] = nextMW;count = count + 1}
  }
  
  
  
}
mwState$DIST_F[mwState$DIST_F == -9] = NA
mwState$DIST_F[mwState$DIST_F > 15] = NA
mwState$DIST_B[mwState$DIST_B == -9] = NA
mwState$DIST_B[mwState$DIST_B >12] = NA

mwState$DIST = mwState$DIST_F
mwState$DIST[!is.na(mwState$DIST_B) & is.na(mwState$DIST_F)] = - mwState$DIST_B[!is.na(mwState$DIST_B) & is.na(mwState$DIST_F)]
mwState$NextMW[mwState$DIST > 0] = NA
colnames(mwState)[colnames(mwState)=="CHANGE"] = "REAL_CHANGE"

mwState$DIST[is.na(mwState$DIST)] = -999
#mwState = mwState[c(1,2,3,7,8,9,12,13,14,15,16)]
```



```{r}
#
data = merge(data, mwState)
data$empW = data$employed * data$EARNWT
data$REF_WAGE = (data$HOURWAGE - data$MW) / data$CPI_FACTOR
data$REF_WAGE[!is.na(data$DIST)][data$DIST[!is.na(data$DIST)] < 0] = (data$HOURWAGE - data$NextMW)[!is.na(data$DIST)][data$DIST[!is.na(data$DIST)] < 0]
data$UHRSWORKORG[data$UHRSWORKORG >= 998] = NA

data$WAGE_BIN = floor(data$REF_WAGE)
data$WAGE_BIN[data$WAGE_BIN > 20] = 20
data$WAGE_BIN[data$WAGE_BIN < -5] = -5

# data2 = aggregate(empW ~ YEAR + QUARTER + STATEFIP + WAGE_BIN + COMP_Q, data=data, FUN=sum)
# library(tidyr)
# # Balance data set:
# data2 = complete(data2, YEAR, QUARTER, STATEFIP, WAGE_BIN, COMP_Q, fill=list(empW=0))
# data2 = filter(data2, (YEAR > 2000) | (QUARTER > 2))
# data2 = merge(data2, pop, all.x=T)
# data2 = merge(data2, subPop, all.x=T)
# data2$POPULATION_SUB[is.na(data2$POPULATION_SUB) | data2$POPULATION_SUB==0] = 1
# data1 = data2
data = data[!colnames(data)%in%c("REAL_CHANGE.1","REAL_CHANGE.2")]
write.csv(data, "IndividualDataConc2Tenths1996.csv",row.names=F)
```


Note: below file names were changed but not actually used
```{r}
data = read.csv("IndividualDataConc2Tenths1996.csv")
data$NextMW[is.na(data$NextMW)] = -1
data$RealMW = data$MW / data$CPI_FACTOR
data1 = aggregate(empW ~ YEAR + QUARTER + STATEFIP + WAGE_BIN + COMP_Q + POPULATION + POPULATION_SUB + NextMW + LastChange + RealMW + BindBefore + REAL_CHANGE + LastChangePct + CHANGE_PCT + DIST + CPI_FACTOR, data=data, FUN=sum)

# data1 = aggregate(empW ~ YEAR + QUARTER + STATEFIP + WAGE_BIN + COMP_Q + POPULATION + POPULATION_SUB, data=data, FUN=sum)
# data1 = merge(data1, mwState)
data1$DIST_YEAR = floor(data1$DIST/4)
data1$EMP_RATE = data1$empW / data1$POPULATION
data1$EMP_RATE_SUB = data1$empW / data1$POPULATION_SUB
data1$EMP_RATE_SUB[is.na(data1$EMP_RATE_SUB)] = 0
write.csv(data1, "EventDataQuarterConc2Tenths1996.csv",row.names=F)
```

Controls:
```{r}
c1 = read.csv("control1.csv")
c1 = c1[c(4,6,9,15,16,(18:26))]
c2 = read.csv("control2.csv")
c2 = c2[c(4,6,9,15,16,(18:40))]
c3 = read.csv("control3.csv")
c3 = c3[c(4,6,9,15,16,(18:40))]
control = merge(c1,c2, all=T)
control = merge(control, c3,all=T)
write.csv(control,"ControlData.csv",row.names=F)
```


New data: need small wage changes for controls, and longer time frame (>=1996 instead of 2000 for event study)
